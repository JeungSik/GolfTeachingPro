package kr.co.anitex.golfteachingpro

import android.annotation.SuppressLint
import android.content.ContentValues
import android.content.Context
import android.content.Intent
import android.content.res.Configuration
import android.database.Cursor
import android.graphics.*
import android.graphics.Color.rgb
import android.hardware.camera2.*
import android.media.Image
import android.media.ImageReader
import android.media.MediaActionSound
import android.net.Uri
import android.os.*
import android.provider.MediaStore
import android.util.Log
import android.util.Size
import android.view.*
import android.widget.ImageButton
import android.widget.Toast
import androidx.activity.OnBackPressedCallback
import androidx.annotation.RequiresApi
import androidx.core.view.isVisible
import androidx.fragment.app.Fragment
import androidx.navigation.NavController
import androidx.navigation.Navigation
import kr.co.anitex.golfteachingpro.utils.AutoFitTextureView
import kr.co.anitex.golfteachingpro.utils.ImageUtils
import com.google.android.gms.ads.AdRequest
import com.google.android.gms.ads.AdView
import kotlinx.android.synthetic.main.fragment_camera.*
import org.opencv.android.OpenCVLoader
import org.opencv.core.Mat
import org.pytorch.IValue
import org.pytorch.Module
import org.pytorch.PyTorchAndroid
import org.pytorch.Tensor
import org.pytorch.torchvision.TensorImageUtils
import java.io.File
import java.nio.ByteBuffer
import java.nio.FloatBuffer
import java.text.SimpleDateFormat
import java.util.*
import java.util.concurrent.Semaphore
import java.util.concurrent.TimeUnit
import kotlin.math.exp
import kotlin.math.max
import kotlin.math.roundToInt


@Suppress("NULLABILITY_MISMATCH_BASED_ON_JAVA_ANNOTATIONS", "DEPRECATION", "SENSELESS_COMPARISON")
@RequiresApi(Build.VERSION_CODES.M)
class CameraFragment : Fragment() {

	private lateinit var mAdView : AdView

	/** Host's navigation controller */
	private val mNavController: NavController by lazy {
		Navigation.findNavController(requireActivity(), R.id.camera_fragment_container)
	}

	/** Overlay on top of the camera preview */
	//private lateinit var mOverlay: View

	/** Where the camera preview is displayed */
	private lateinit var mViewFinder: AutoFitTextureView
	// private lateinit var viewFinder: SurfaceView

	/** [CameraCharacteristics] corresponding to the provided Camera ID */
	//private val mCharacteristics: CameraCharacteristics by lazy {
	//	mCameraManager.getCameraCharacteristics(mCameraId)
	//}

	/** Detects, characterizes, and connects to a CameraDevice (used for all camera operations) */
	private val mCameraManager: CameraManager by lazy {
		val context = requireContext().applicationContext
		context.getSystemService(Context.CAMERA_SERVICE) as CameraManager
	}

	/** ID of the current [CameraDevice].   */
	private lateinit var mCameraId: String

	/** The [android.util.Size] of camera preview.	*/
	private lateinit var mPreviewSize: Size

	/** A [Semaphore] to prevent the app from exiting before closing the camera.	*/
	private val mCameraOpenCloseLock = Semaphore(1)

	/** A reference to the opened [CameraDevice].	*/
	private var mCameraDevice: CameraDevice? = null

	/** [android.hardware.camera2.CaptureRequest.Builder] for the camera preview	*/
	private var mPreviewRequestBuilder: CaptureRequest.Builder? = null

	/** An [ImageReader] that handles preview frame capture.	*/
	private var mPreviewReader: ImageReader? = null

	/** [HandlerThread] where all camera operations run */
	private val mCameraThread = HandlerThread("CameraThread").apply { start() }

	/** [Handler] corresponding to [mCameraThread] */
	private val mCameraHandler = Handler(mCameraThread.looper)

	/** A [CameraCaptureSession] for camera preview.	*/
	private var mCaptureSession: CameraCaptureSession? = null

	/** [CaptureRequest] generated by [.previewRequestBuilder]	*/
	private var mPreviewRequest: CaptureRequest? = null

	/** Camera Recording State	*/
	private var mRecordingCarmera = false

	/** File where the recording will be saved */
	private lateinit var mOutputFile: File
	private lateinit var mOutputFileUri: Uri

	/** Camera LENS Change Button  */
	private var mSwitchCamera: ImageButton? = null

	private var mMediaEncoder: MediaEncoder? = null
	private lateinit var mImageFrame: Mat

	private var mOrientation: Int = Configuration.ORIENTATION_UNDEFINED
	//private var mDoEncodingFinished = true
	private val mDoEncodingFinishedLock = Semaphore(1)

	private var mPaused = false

	/** AI Model related*/
	private lateinit var mAImodule: Module				// AI module
	private var mBuffer: FloatBuffer = Tensor.allocateFloatBuffer(AI_SEQUENCE_LEN * AI_FRAME_SIZE)
	private var mTempBuffer: FloatBuffer = Tensor.allocateFloatBuffer((AI_SEQUENCE_LEN -1) * AI_FRAME_SIZE)
	private var mTempFloatArray = FloatArray(AI_FRAME_SIZE)
	private var mTwoBuffer: FloatBuffer = Tensor.allocateFloatBuffer(2 * AI_FRAME_SIZE)
	private val mArrayTensor: Tensor = Tensor.fromBlob(mTwoBuffer, longArrayOf(1, 2, 3, 160, 160))
	private var mBufferIndex = 0
	private var mAddressPoseDetect = false
	private var mFinishPoseDetect = false
	private var mEndToFinishDetect = false

	/** Find Camera ID of the requseted camera face	*/
	private fun getCameraId(reqCameraFace: Int): String? {
		try{
			for (id in mCameraManager.cameraIdList) {
				val characteristics = mCameraManager.getCameraCharacteristics(id)
				val face = characteristics.get(CameraCharacteristics.LENS_FACING)

				if (face == reqCameraFace) return id
			}
		} catch (e: CameraAccessException) {
			e.printStackTrace()
		}
		return null
	}

	/**
	 * Compares two `Size`s based on their areas.
	 */
	//internal class CompareSizesByArea : Comparator<Size> {
	//	override fun compare(lhs: Size, rhs: Size): Int {
			// We cast here to ensure the multiplications won't overflow
	//		return java.lang.Long.signum(
	//			lhs.width.toLong() * lhs.height - rhs.width.toLong() * rhs.height
	//		)
	//	}
	//}

	/** Find the optimal preview size	*/
	//private fun getOptimalSize(choices: Array<Size>, width: Int, height: Int, aspectRatio: Size): Size {
		// Collect the supported resolutions that are at least as big as the preview Surface
	//	val bigEnough: MutableList<Size> = ArrayList()

	//	for (option in choices) {
	//		if (option.height >= MINIMUM_PREVIEW_SIZE && option.width >= MINIMUM_PREVIEW_SIZE) {
	//			if(VERBOSE) Log.d(TAG, "Adding size: " + option.width + "X" + option.height)
	//			bigEnough.add(option)
	//		} else {
	//			if(VERBOSE) Log.d(TAG, "Skipped size: " + option.width + "X" + option.height)
	//		}
	//	}

		// Pick the smallest of those, assuming we found any
	//	return if (bigEnough.size > 0) {
	//		val chosenSize = Collections.min(bigEnough, CompareSizesByArea())
	//		if(VERBOSE) Log.d(TAG, "Chosen size: " + chosenSize.width + "X" + chosenSize.height)
	//		chosenSize
	//	} else {
	//		if(VERBOSE) Log.d(TAG, "Couldn't find any suitable preview size")
	//		choices[0]
	//	}
	//}

	/**
	 * Compares two `Size.width`s based on their areas.
	 */
	internal class CompareSizesByWidth : Comparator<Size> {
		override fun compare(lhs: Size, rhs: Size): Int {
			// We cast here to ensure the multiplications won't overflow
			return java.lang.Long.signum(lhs.width.toLong() - rhs.width.toLong())
		}
	}

	/** Find the optimal preview size	*/
	private fun getClosestSize(choices: Array<Size>): Size {
		// Collect the supported resolutions that are at least as big as the preview Surface
		val bigEnough: MutableList<Size> = ArrayList()

		for (option in choices) {
			if (option.width >= PREVIEW_WIDTH && option.height >= PREVIEW_HEIGHT) {
				if(VERBOSE) Log.d(TAG, "Adding size: " + option.width + "X" + option.height)
				bigEnough.add(option)
			} else {
				if(VERBOSE) Log.d(TAG, "Skipped size: " + option.width + "X" + option.height)
			}
		}

		// Pick the smallest of those, assuming we found any
		return if (bigEnough.size > 0) {
			val chosenSize = Collections.min(bigEnough, CompareSizesByWidth())
			if(VERBOSE) Log.d(TAG, "Chosen size: ${chosenSize.width} X ${chosenSize.height}")
			chosenSize
		} else {
			if(VERBOSE) Log.d(TAG, "Couldn't find any suitable preview size")
			choices[0]
		}
	}

	private fun setupCameraOutputs(/*width: Int, height: Int*/) {
		try {
			if(VERBOSE) Log.d(TAG, "Setup Camera Facing: $mCameraFacing")
			mCameraId = getCameraId(mCameraFacing)!!

			val characteristics = mCameraManager.getCameraCharacteristics(mCameraId)
			val map = characteristics.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP)

			// For still image captures, we use the largest available size.
			/*
			val largest = Collections.max(
			Arrays.asList(*map?.getOutputSizes(ImageFormat.YUV_420_888)),
			CompareSizesByArea())

			if(VERBOS) Log.d(TAG, "Largest Size : ${largest.width} X ${largest.height}")
			*/

			// Danger, W.R.! Attempting to use too large a preview size could  exceed the camera
			// bus' bandwidth limitation, resulting in gorgeous previews but the storage of
			// garbage capture data.
			//previewSize = getOptimalSize(map?.getOutputSizes(SurfaceTexture::class.java)!!, width, height, largest)
			mPreviewSize = getClosestSize(map?.getOutputSizes(SurfaceTexture::class.java)!!)

			// We fit the aspect ratio of TextureView to the size of preview we picked.
			mOrientation = resources.configuration.orientation
			if(VERBOSE) Log.d(TAG, "Orientation : $mOrientation")

			if (mOrientation == Configuration.ORIENTATION_LANDSCAPE) {
				mViewFinder.setAspectRatio(mPreviewSize.width, mPreviewSize.height)
			} else {
				mViewFinder.setAspectRatio(mPreviewSize.height, mPreviewSize.width)
			}
			return
		} catch (e: CameraAccessException) {
			Log.d(TAG, "CameraAccessException : ${e.message}")
		} catch (e: NullPointerException) {
			// Currently an NPE is thrown when the Camera2API is used but not supported on the
			// device this code runs.
			//ErrorDialog.newInstance(getString(R.string.camera_error)).show(getChildFragmentManager(), FRAGMENT_DIALOG);
			Log.d(TAG, "NullPointerException : ${e.message}")
		}
	}

	/**
	 * Configures the necessary [android.graphics.Matrix] transformation to `mTextureView`.
	 * This method should be called after the camera preview size is determined in
	 * setupCameraOutputs and also the size of `mTextureView` is fixed.
	 *
	 * @param viewWidth  The width of `mTextureView`
	 * @param viewHeight The height of `mTextureView`
	 */
	private fun configureTransform(viewWidth: Int, viewHeight: Int) {
		// Check null value of viewFinder and previewSize
		if (mPreviewSize == null) return
		if(VERBOSE) Log.d(TAG, "ViewFinder Size: ${mViewFinder.width} X ${mViewFinder.height}")
		if(VERBOSE) Log.d(TAG, "configureTransform parameter Size: $viewWidth X $viewHeight")

		val window = context?.getSystemService(Context.WINDOW_SERVICE) as WindowManager
		val display = window.defaultDisplay
		val rotation = display.rotation
		val matrix = Matrix()
		val viewRect = RectF(0F, 0F, viewWidth.toFloat(), viewHeight.toFloat())
		val bufferRect = RectF(
			0F,
			0F,
			mPreviewSize.width.toFloat(),
			mPreviewSize.height.toFloat()
		)
		val centerX = viewRect.centerX()
		val centerY = viewRect.centerY()

		if(VERBOSE) Log.d(TAG, "Display rotation : $rotation")
		if (rotation == Surface.ROTATION_90 || rotation == Surface.ROTATION_270) {
			bufferRect.offset(centerX - bufferRect.centerX(), centerY - bufferRect.centerY())
			matrix.setRectToRect(viewRect, bufferRect, Matrix.ScaleToFit.FILL)
			val scale = max(
				viewHeight.toFloat() / mPreviewSize.height,
				viewWidth.toFloat() / mPreviewSize.width
			)
			matrix.postScale(scale, scale, centerX, centerY)
			matrix.postRotate(90 * (rotation - 2).toFloat(), centerX, centerY)
		} else if (Surface.ROTATION_180 == rotation) {
				matrix.postRotate(180f, centerX, centerY)
		}

		mViewFinder.setTransform(matrix)
	}

	private fun processImage(mat: Mat) {
		mImageFrame = mat
		// mDoEncodingFinished = false
		try {
			if (!mDoEncodingFinishedLock.tryAcquire(500, TimeUnit.MILLISECONDS)) {
				throw RuntimeException("Time out waiting to lock DoEncodingFinishedLock.............")
			}
			//mDoEncodingFinished = mMediaEncoder!!.doEncodeVideoFromBuffer(mImageFrame, false)
			mMediaEncoder!!.doEncodeVideoFromBuffer(mImageFrame, false)
			mDoEncodingFinishedLock.release()
		} catch (e: Exception) {
			Log.d(TAG, "Exception : ${e.message}")
		} catch (e: InterruptedException) {
			throw RuntimeException("Interrupted while trying to lock processImage.", e)
		}
	}

	private fun preprocessImage(image: Image): Bitmap? {
		var bitmap: Bitmap? = ImageUtils.imgToBitmap(image)
		val matrix = Matrix()

		if (mCameraFacing == FRONTSIDE_CAMERA) {
			matrix.postRotate(270.0f)
		} else {
			matrix.postRotate(90.0f)
		}

		matrix.postScale(
			SCALE_WIDTH.coerceAtMost(SCALE_HEIGHT),
			SCALE_WIDTH.coerceAtMost(SCALE_HEIGHT)
		)

		/*
		if (mCameraFacing == FRONTSIDE_CAMERA) {
			val cx = SCALE_WIDTH.coerceAtMost(SCALE_HEIGHT) / 2f
			val cy = SCALE_WIDTH.coerceAtMost(SCALE_HEIGHT) / 2f
			matrix.postScale(1F, -1F, cx, cy)
		}
		*/

		bitmap = Bitmap.createBitmap(
			bitmap!!,
			0,
			0,
			bitmap.width,
			bitmap.height,
			matrix,
			true
		)

		val resizedBitmap = Bitmap.createBitmap(
			AI_IMAGE_SIZE,
			AI_IMAGE_SIZE,
			Bitmap.Config.ARGB_8888
		)
		val canvas = Canvas(resizedBitmap)
		canvas.drawBitmap(
			bitmap,
			((AI_IMAGE_SIZE - bitmap.width) / 2).toFloat(),
			((AI_IMAGE_SIZE - bitmap.height) / 2).toFloat(),
			null
		)

		return resizedBitmap
	}

	private fun floatArrayToGrayscaleBitmap(
		floatArray: FloatArray,
		width: Int,
		height: Int,
		alpha: Byte = (255).toByte(),
		reverseScale: Boolean = false
	) : Bitmap {

		// Create empty bitmap in RGBA format (even though it says ARGB but channels are RGBA)
		val bmp = Bitmap.createBitmap(width, height, Bitmap.Config.ARGB_8888)
		val byteBuffer = ByteBuffer.allocate(width * height * 4)

		// mapping smallest value to 0 and largest value to 255
		val maxValue = floatArray.maxOrNull() ?: 1.0f
		val minValue = floatArray.minOrNull() ?: 0.0f
		val delta = maxValue-minValue
		var tempValue :Byte

		// Define if float min..max will be mapped to 0..255 or 255..0
		val conversion = when(reverseScale) {
			false -> { v: Float -> ((v - minValue) / delta * 255).toInt().toByte() }
			true -> { v: Float -> (255 - (v - minValue) / delta * 255).toInt().toByte() }
		}

		// copy each value from float array to RGB channels and set alpha channel
		floatArray.forEachIndexed { i, value ->
			tempValue = conversion(value)
			byteBuffer.put(4 * i, tempValue)
			byteBuffer.put(4 * i + 1, tempValue)
			byteBuffer.put(4 * i + 2, tempValue)
			byteBuffer.put(4 * i + 3, alpha)
		}

		bmp.copyPixelsFromBuffer(byteBuffer)

		return bmp
	}

	private fun floatArrayToBitmap(floatArray: FloatArray, width: Int, height: Int) : Bitmap {

		// Create empty bitmap in ARGB format
		val bmp: Bitmap = Bitmap.createBitmap(width, height, Bitmap.Config.ARGB_8888)
		val pixels = IntArray(width * height * 4)

		// mapping smallest value to 0 and largest value to 255
		val maxValue = floatArray.maxOrNull() ?: 1.0f
		val minValue = floatArray.minOrNull() ?: -1.0f
		val delta = maxValue - minValue

		// Define if float min..max will be mapped to 0..255 or 255..0
		val conversion = { v: Float -> ((v - minValue) / delta * 255.0f).roundToInt() }

		// copy each value from float array to RGB channels
		for (i in 0 until width * height) {
			val r = conversion(floatArray[i])
			val g = conversion(floatArray[i + width * height])
			val b = conversion(floatArray[i + 2 * width * height])
			pixels[i] = rgb(r, g, b) // you might need to import for rgb()
		}
		bmp.setPixels(pixels, 0, width, 0, 0, width, height)

		return bmp
	}

	/** softmax function */
	private fun softmax(inputs: FloatArray): FloatArray {
		var total = 0F
		val outputs = FloatArray(inputs.size)

		for(i in inputs.indices){
			total += exp(inputs[i])
		}
		for(i in inputs.indices) {
			outputs[i] = exp(inputs[i]) / total
		}
		return outputs
	}

	/** argmax function */
	private fun argmax(inputs: FloatArray): Int {
		var maxIndex = 0
		for (i in inputs.indices) {
			if (inputs[maxIndex] < inputs[i]) {
				maxIndex = i
			}
		}
		return maxIndex
	}

	/** Camera Image PreviewListener */
	@SuppressLint("SetTextI18n")
	private val mOnGetPreviewListener: ImageReader.OnImageAvailableListener =
		ImageReader.OnImageAvailableListener { reader ->
			//val acquiredImage = reader.acquireLatestImage()
			val acquiredImage = reader.acquireNextImage()
			if (mRecordingCarmera) {
				if(acquiredImage != null) {
					if(VERBOSE) Log.d(TAG, "Add image frame....")

					//< Start pose detection code -----------------------------------------------------
					if(mAImode) {
						val startTime = System.currentTimeMillis()
						val image = preprocessImage(acquiredImage)
						val inputTensor: Tensor = TensorImageUtils.bitmapToFloat32Tensor(
							image,
							TensorImageUtils.TORCHVISION_NORM_MEAN_RGB,
							TensorImageUtils.TORCHVISION_NORM_STD_RGB,
						)

						if (mBufferIndex < AI_SEQUENCE_LEN) {
							mBuffer.position(mBufferIndex * AI_FRAME_SIZE)
							mBuffer.put(inputTensor.dataAsFloatArray)
						} else {
							// decode inputTensor Image
							/*
							for(i in 0..7) {
								val tempBuffer: FloatArray = FloatArray(mFrameSize)
								mBuffer.position(i * mFrameSize)
								mBuffer.get(tempBuffer)
								val floatImage = floatArrayToBitmap(tempBuffer, 160, 160)
								if(VERBOSE) Log.d(TAG, "image frame....")
							}
							*/

							mBuffer.position((mBufferIndex % AI_SEQUENCE_LEN) * AI_FRAME_SIZE)
							mBuffer.put(inputTensor.dataAsFloatArray)

							val endTime = System.currentTimeMillis()
							if (VERBOSE) Log.d(TAG, "Buffer Shift Time  ----------------- 소요시간(${endTime-startTime})")

							// decode inputTensor Image
/*
							for(i in 0..7) {
								val tempBuffer: FloatArray = FloatArray(mFrameSize)
								mBuffer.position(i * mFrameSize)
								mBuffer.get(tempBuffer)
								val floatImage = floatArrayToBitmap(tempBuffer, 160, 160)
								if(VERBOSE) Log.d(TAG, "image frame....")
							}
*/
						}

						mBufferIndex += 1

						// complete to make Input data
						if (mBufferIndex >= AI_SEQUENCE_LEN) {
							mBuffer.position((mBufferIndex % AI_SEQUENCE_LEN) * AI_FRAME_SIZE)
							mBuffer.get(mTempFloatArray, 0, AI_FRAME_SIZE)
							mTwoBuffer.position(0)
							mTwoBuffer.put(mTempFloatArray, 0, AI_FRAME_SIZE)
							mTwoBuffer.put(inputTensor.dataAsFloatArray)

							val outputTensor =
								mAImodule.forward(IValue.from(mArrayTensor)).toTensor()
							val outputs = softmax(outputTensor.dataAsFloatArray)
							val result = argmax(outputs)
							val endTime = System.currentTimeMillis()
							if (VERBOSE) Log.d(TAG, "AI Golf Pose Detection Result : $result  ----------------- 소요시간(${endTime-startTime})")
							if (result == 0 && outputs[result] >= AI_ACCURACY && !mAddressPoseDetect) {
								mAddressPoseDetect = true
								Handler(Looper.getMainLooper()).post { progressBar_cyclic.visibility = View.INVISIBLE }

								// Play Sound Effect to Start Video Recording
								sound.play(MediaActionSound.SHUTTER_CLICK)
								Handler(Looper.getMainLooper()).post {
									recording_notify.visibility = View.VISIBLE
									recording_time_signal.text = "REC"
								}

								startVideoRecording()

								// Start recording timer
								mRecordingTimer.start()
								mRecordingStartMillis = System.currentTimeMillis()

								if (VERBOSE) Log.d(TAG, "Video Recording started!!!!!")

								// Button image change
								Handler(Looper.getMainLooper()).post {
									recording_button.visibility = View.INVISIBLE
									recording_button.isEnabled = false
									recording_button.isSelected = true
								}

							} else if(result == 7 && outputs[result] >= AI_ACCURACY && !mFinishPoseDetect) {
								if (mAddressPoseDetect) {
									mFinishPoseDetect = true
								}
							} else if(result == 8 && outputs[result] >= AI_ACCURACY && mFinishPoseDetect) {
								mEndToFinishDetect = true
							}
						}

						if(mEndToFinishDetect && recording_button.isEnabled) {
							// Play Sound Effect to Stop Video Recording
							sound.play(MediaActionSound.STOP_VIDEO_RECORDING)
							Handler(Looper.getMainLooper()).post {
								recording_notify.visibility = View.INVISIBLE
								ai_mode_text.visibility = View.VISIBLE
								ai_mode_switch.visibility = View.VISIBLE
								switch_camera_button.visibility = View.VISIBLE
								recording_button.isSelected = false
							}

							if (stopVideoRecording()) {
								if (VERBOSE) Log.d(TAG, "Video Recording Success!!!!!")

								// Set parameter and Launch player fragment
								val action =
									CameraFragmentDirections.actionCameraToPlayer(
										mOutputFile.absolutePath
									)
								//mNavController.navigate(action)
								Handler(Looper.getMainLooper()).post { mNavController.navigate(action) }

							} else {
								if (VERBOSE) Log.d(TAG, "Video Recording Fail!!!!!")
							}
						}
					}
					//---------------------------------------------------------------------------------

					if(mRecordingCarmera) {
						if(!mAImode) {
							//val image = preprocessImage(acquiredImage)
							val mat = if (mCameraFacing == FRONTSIDE_CAMERA) {
								//Core.flip(mat, mat, -1)
								//Core.rotate(mat, mat, Core.ROTATE_180)
								ImageUtils.imageToMatDegree180(acquiredImage)
							}else{
								ImageUtils.imageToMat(acquiredImage)
							}
							//processImage(ImageUtils.imageToMat(i)!!)
							processImage(mat)
						} else {
							if(mAddressPoseDetect) {
								if(!mEndToFinishDetect || !recording_button.isEnabled) {
									val mat = if (mCameraFacing == FRONTSIDE_CAMERA) {
										//Core.flip(mat, mat, -1)
										ImageUtils.imageToMatDegree180(acquiredImage)
									} else {
										ImageUtils.imageToMat(acquiredImage)
									}
									//processImage(ImageUtils.imageToMat(i)!!)
									processImage(mat)
								}
							}
						}
					}
				}
			}
			acquiredImage?.close()
		}

	/** Shows a [Toast] on the UI thread.	*/
	private fun showToast(text: String) {
		Handler(context?.mainLooper!!).post {
			Toast.makeText(context?.applicationContext, text, Toast.LENGTH_SHORT).show()
		}
	}

	private val mCaptureCallback: CameraCaptureSession.CaptureCallback = object : CameraCaptureSession.CaptureCallback() {
		override fun onCaptureProgressed(
			session: CameraCaptureSession,
			request: CaptureRequest,
			partialResult: CaptureResult
		) {
		}

		override fun onCaptureCompleted(
			session: CameraCaptureSession,
			request: CaptureRequest,
			result: TotalCaptureResult
		) {
		}
	}

	/**
	 * Creates a new [CameraCaptureSession] for camera preview.
	 */
	@SuppressLint("LongLogTag")
	private fun createCameraPreviewSession() {
		try {
			val texture = mViewFinder.surfaceTexture!!

			// We configure the size of default buffer to be the size of camera preview we want.
			texture.setDefaultBufferSize(mPreviewSize.width, mPreviewSize.height)

			// This is the output Surface we need to start preview.
			val surface = Surface(texture)

			// We set up a CaptureRequest.Builder with the output Surface.
			mPreviewRequestBuilder = mCameraDevice!!.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW)

			// Add preview surface
			mPreviewRequestBuilder?.addTarget(surface)

			if(VERBOSE)
				Log.d(TAG, "Opening camera preview: ${mPreviewSize.width} X ${mPreviewSize.height}")

			// Create the reader for the preview frames.
			mPreviewReader = ImageReader.newInstance(
				mPreviewSize.width, mPreviewSize.height, ImageFormat.YUV_420_888, 1
			)
			mPreviewReader?.setOnImageAvailableListener(mOnGetPreviewListener, mCameraHandler)

			// Add preview image reader surface
			mPreviewRequestBuilder?.addTarget(mPreviewReader?.surface!!)

			// Here, we create a CameraCaptureSession for camera preview.
			mCameraDevice!!.createCaptureSession(
				listOf(surface, mPreviewReader?.surface),
				object : CameraCaptureSession.StateCallback() {
					override fun onConfigured(cameraCaptureSession: CameraCaptureSession) {
						// The camera is already closed
						if (mCameraDevice == null) return

						// When the session is ready, we start displaying the preview.
						mCaptureSession = cameraCaptureSession

						try {
							// Auto focus should be continuous for camera preview.
							mPreviewRequestBuilder?.set(
								CaptureRequest.CONTROL_AF_MODE,
//								CaptureRequest.CONTROL_AF_MODE_AUTO)
								CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_VIDEO
							)

							// Flash is automatically enabled when necessary.
							mPreviewRequestBuilder?.set(
								CaptureRequest.CONTROL_AE_MODE,
								CaptureRequest.CONTROL_AE_MODE_ON
							)
// 							    CaptureRequest.CONTROL_AE_MODE_ON_AUTO_FLASH)

							// Finally, we start displaying the camera preview.
							mPreviewRequest = mPreviewRequestBuilder?.build()
							mCaptureSession!!.setRepeatingRequest(
								mPreviewRequest!!, mCaptureCallback, mCameraHandler
							)

						} catch (e: CameraAccessException) {
							Log.d(TAG, "Exception : ${e.message}")
						}
					}

					override fun onConfigureFailed(cameraCaptureSession: CameraCaptureSession) {
						showToast("Create capture session failed!")
					}
				},
				null
			)
		} catch (e: CameraAccessException) {
			Log.d(TAG, "Exception : ${e.message}")
		}
		//mOnGetPreviewListener.initialize(getApplicationContext(), getAssets(), mScoreView, inferenceHandler);
	}

	/**
	 * [android.hardware.camera2.CameraDevice.StateCallback]
	 * is called when [CameraDevice] changes its state.
	 */
	private val mCameraDeviceStateCallback: CameraDevice.StateCallback = object : CameraDevice.StateCallback() {
		override fun onOpened(cd: CameraDevice) {
			// This method is called when the camera is opened.  We start camera preview here.
			mCameraOpenCloseLock.release()
			mCameraDevice = cd
			createCameraPreviewSession()
		}

		override fun onDisconnected(cd: CameraDevice) {
			mCameraOpenCloseLock.release()
			//cd.close()
			mCameraDevice!!.close()
			mCameraDevice = null
			if (mOnGetPreviewListener != null) {
				//mOnGetPreviewListener.deInitialize();
			}
		}

		override fun onError(cd: CameraDevice, error: Int) {
			mCameraOpenCloseLock.release()
			//cd.close()
			mCameraDevice!!.close()
			mCameraDevice = null
			if (mOnGetPreviewListener != null) {
				//mOnGetPreviewListener.deInitialize();
			}
		}
	}

	@SuppressLint("MissingPermission")
	private fun openCamera(width: Int, height: Int) {
		// Setup camera and preview size
		if(VERBOSE) Log.d(TAG, "Open Camera Size : $width X $height")

		setupCameraOutputs(/*width, height*/)
		configureTransform(width, height)
		//configureTransform(mPreviewSize.width, mPreviewSize.height)

		try {
			if (!mCameraOpenCloseLock.tryAcquire(2500, TimeUnit.MILLISECONDS)) {
				throw RuntimeException("Time out waiting to lock camera opening.")
			}
			mCameraManager.openCamera(mCameraId, mCameraDeviceStateCallback, mCameraHandler)
			if(VERBOSE) Log.d(TAG, "Open camera success!!!!!")
		} catch (e: CameraAccessException) {
			Log.d(TAG, "Exception : ${e.message}")
		} catch (e: InterruptedException) {
			throw RuntimeException("Interrupted while trying to lock camera opening.", e)
		}
	}

	/**
	 * [android.view.TextureView.SurfaceTextureListener] handles several lifecycle events on a
	 * [TextureView].
	 */
	private val mSurfaceTextureListener: TextureView.SurfaceTextureListener = object :
		TextureView.SurfaceTextureListener {
		override fun onSurfaceTextureAvailable(texture: SurfaceTexture, width: Int, height: Int) {
			if(VERBOSE) Log.d(TAG, "TextureView Size : $width X $height")
			//openCamera(width, height)
			openCamera(mViewFinder.width, mViewFinder.height)
		}

		override fun onSurfaceTextureSizeChanged(
			texture: SurfaceTexture, width: Int, height: Int
		) {
			configureTransform(width, height)
			//configureTransform(mPreviewSize.width, mPreviewSize.height)
		}

		override fun onSurfaceTextureDestroyed(texture: SurfaceTexture): Boolean {
			return true
		}

		override fun onSurfaceTextureUpdated(texture: SurfaceTexture) {}
	}

	/** Timer for Recording time display	*/
	private var mDuration = 0
	private val mRecordingTimer = object: CountDownTimer(Long.MAX_VALUE, COUNTDOWN_INTERVAL) {

		@SuppressLint("SetTextI18n")
		override fun onTick(millisUntilFinished: Long) {
			val basetime = Long.MAX_VALUE - millisUntilFinished
			val mil = ((basetime % 1000) / 10).toInt()
			val sec = ((basetime / 1000) % 60).toInt()
			val min = ((basetime / 1000) / 60).toInt()

			mDuration = mil + (sec * 1000) + (min * 60000)
			//timerText!!.text = "%02d:%02d:%02d".format(min, sec, mil)
			recording_time_text.text = "%02d:%02d.%02d".format(min, sec, mil)

			if( mil < 60 ){
				//timerSignal!!.visibility = View.VISIBLE
				recording_time_signal.visibility = View.VISIBLE
				//recording_notify.visibility = View.VISIBLE
			}else {
				//timerSignal!!.visibility = View.INVISIBLE
				recording_time_signal.visibility = View.INVISIBLE
				//recording_notify.visibility = View.INVISIBLE
			}

			if(!recording_button.isEnabled && sec >= 1) {
				recording_button.visibility = View.VISIBLE
				recording_button.isEnabled = true
			}
		}

		@SuppressLint("SetTextI18n")
		override fun onFinish() {
			try {
				recording_time_text.text = "00:00:00"
				recording_time_signal.visibility = View.INVISIBLE
			} catch (e: Exception) {
				Log.e(TAG, "onFinish Exception : ${e.message}")
			}
		}
	}

	private var mRecordingStartMillis: Long = 0L

	/** Camera face change switch 	*/
	private fun switchCameras() {
		mCameraFacing = if(mCameraFacing == FRONTSIDE_CAMERA) {
			BACKSIDE_CAMERA
		} else {
			FRONTSIDE_CAMERA
		}

		mCameraId = getCameraId(mCameraFacing)!!

		if(VERBOSE) Log.d(TAG, "Switch Camera Facing : $mCameraFacing")

		mCaptureSession!!.close()
		mCaptureSession = null
		mCameraDevice!!.close()
		mCameraDevice = null

		openCamera(mViewFinder.width, mViewFinder.height)
	}

	@SuppressLint("Recycle")
	private fun getPath(context: Context, uri: Uri): String? {
		val projection = arrayOf(MediaStore.Video.Media.DATA)
		val cursor: Cursor =
			context.contentResolver.query(uri, projection, null, null, null) ?: return null
		val column_index: Int = cursor.getColumnIndexOrThrow(MediaStore.Video.Media.DATA)
		cursor.moveToFirst()
		val s: String = cursor.getString(column_index)
		cursor.close()
		return s
	}

	/** Creates a [File] named with the current date and time */
	private fun createFile(context: Context, folder: String): File {
		val sdf = SimpleDateFormat("yyyyMMdd_HHmmss", Locale.US)
		val filename = "VID_${sdf.format(Date())}.mp4"

		// Create Video file in MediaStore
		val values = ContentValues().apply {
			put(MediaStore.Video.Media.RELATIVE_PATH, "${Environment.DIRECTORY_MOVIES}/$folder")
			put(MediaStore.Video.Media.DISPLAY_NAME, filename)
			put(MediaStore.Video.Media.MIME_TYPE, "video/*")
			put(MediaStore.Video.Media.WIDTH, PREVIEW_HEIGHT)
			put(MediaStore.Video.Media.HEIGHT, PREVIEW_WIDTH)
			//put(MediaStore.Video.Media.IS_PENDING, 1)
		}

		mOutputFileUri = context.contentResolver.insert(
			MediaStore.Video.Media.EXTERNAL_CONTENT_URI,
			values
		)!!

		val path = getPath(context, mOutputFileUri)
		if(VERBOSE) Log.d(TAG, "Create Video File Uri : $path")

		return File(path)
	}

	private fun startVideoRecording(){
		// Create File name
		mOutputFile = createFile(requireContext(), APP_NAME)

		// Create MediaEncodeDecode and Set output file name
		mMediaEncoder = MediaEncoder(mOutputFile, mOrientation)

		try {
			mMediaEncoder!!.initMediaEncoder(
				PREVIEW_WIDTH,
				PREVIEW_HEIGHT,
				RECORDER_VIDEO_BITRATE
			)
		} catch (throwable: Throwable) {
			throwable.printStackTrace()
		}
	}

	private fun stopVideoRecording() : Boolean{
		// Stop recording video
		mRecordingCarmera = false

		//val duration = recording_time_text.text
		// Stop recording timer
		mRecordingTimer.onFinish()
		mRecordingTimer.cancel()

		try {
			if (!mDoEncodingFinishedLock.tryAcquire(500, TimeUnit.MILLISECONDS)) {
				throw RuntimeException("Time out waiting to lock DoEncodingFinishedLock.............")
			}

			// final encoding
			mMediaEncoder!!.doEncodeVideoFromBuffer(mImageFrame, true)
			mDoEncodingFinishedLock.release()

			if (VERBOSE) Log.d(TAG, "Saved Video File : ${mOutputFile.absolutePath}")
			if (VERBOSE) Log.d(TAG, "Video Recording stopped!!!!!")

			// Update Saved Video File Info in MediaStore
			val values = ContentValues().apply {
				put(MediaStore.Video.Media.DATA, mOutputFile.absolutePath)
				put(MediaStore.Video.Media.DURATION, mDuration)
				put(MediaStore.Video.Media.IS_PENDING, 0)
			}

			requireContext().contentResolver.update(
				mOutputFileUri, values, null, null
			)

			/*
			MediaScannerConnection.scanFile(requireContext(), arrayOf(mOutputFile.absolutePath), null,
				MediaScannerConnection.OnScanCompletedListener { path: String?, uri: Uri ->
					if(VERBOSE) Log.d(TAG, "Content Resolver Return Uri : $uri")
					requireContext().contentResolver.update(
						uri, values, null, null
					)
				})
			*/

			return true
		} catch (e: Exception) {
			Log.d(TAG, "Exception : ${e.message}")
		} catch (e: InterruptedException) {
			throw RuntimeException("Interrupted while trying to lock processImage.", e)
		}
		return false
	}

	// Start Camera Fragment ----------------------------------------------------------------------
	override fun onCreate(savedInstanceState: Bundle?) {
		super.onCreate(savedInstanceState)

		// This callback will only be called when MyFragment is at least Started.
		val callback: OnBackPressedCallback =
			object : OnBackPressedCallback(true /* enabled by default */) {
				override fun handleOnBackPressed() {
					// Handle the back button event
					if (mRecordingCarmera) {
						if(!mAImode) {
							// Stop recording timer
							if (stopVideoRecording()) {
								if (VERBOSE) Log.d(TAG, "Video Recording Success!!!!!")
								// Delete recording file
								if(mOutputFileUri != null) {
									//mOutputFile.delete()
									requireContext().contentResolver.delete(mOutputFileUri, null, null)
								}
								if (VERBOSE) Log.d(TAG, "Delete Saved Video Recording File!!!!!")
							} else {
								if (VERBOSE) Log.d(TAG, "Video Recording Fail!!!!!")
							}
						}else if(mAddressPoseDetect && !mFinishPoseDetect){
							// Stop recording timer
							if (stopVideoRecording()) {
								if (VERBOSE) Log.d(TAG, "Video Recording Success!!!!!")
								// Delete recording file
								if (mOutputFileUri != null) {
									//mOutputFile.delete()
									requireContext().contentResolver.delete(
										mOutputFileUri,
										null,
										null
									)
								}
								if (VERBOSE) Log.d(TAG, "Delete Saved Video Recording File!!!!!")
							} else {
								if (VERBOSE) Log.d(TAG, "Video Recording Fail!!!!!")
							}
						}else if(!mAddressPoseDetect) {
							// Stop recording video
							mRecordingCarmera = false
						}
					}
					val intent = Intent(requireContext(), MainActivity::class.java)
					startActivity(intent)
				}
			}
		requireActivity().onBackPressedDispatcher.addCallback(this, callback)
	}

	override fun onCreateView(
		inflater: LayoutInflater,
		container: ViewGroup?,
		savedInstanceState: Bundle?
	): View? = inflater.inflate(R.layout.fragment_camera, container, false)

	@SuppressLint("MissingPermission", "ClickableViewAccessibility", "SetTextI18n")
	override fun onViewCreated(view: View, savedInstanceState: Bundle?) {
		super.onViewCreated(view, savedInstanceState)

		// Set AdMob
		mAdView = view.findViewById(R.id.adView)
		val adRequest = AdRequest.Builder().build()
		mAdView.loadAd(adRequest)

		if (!OpenCVLoader.initDebug()) Log.d(TAG, "ERROR : Unable to load OpenCV")
		else Log.d(TAG, "SUCCESS : OpenCV loaded")
		mPaused = false

		//overlay = view.findViewById(R.id.overlay)
		mViewFinder = view.findViewById(R.id.view_finder)

		if(VERBOSE) {
			Log.d(TAG, "mViewFinder isAvailable : ${mViewFinder.isAvailable}")
			Log.d(TAG, "mViewFinder Visible : ${mViewFinder.isVisible}")
		}

		if(mViewFinder.isAvailable) {
			openCamera(mViewFinder.width, mViewFinder.height)
		} else {
			if(VERBOSE) Log.d(TAG, "Set surfaceTextureListener!!!!!!")
			mViewFinder.surfaceTextureListener = mSurfaceTextureListener
		}

		ai_mode_switch.isChecked = mAImode
		if (mAImode) ai_mode_switch.text = "ON"
		else ai_mode_switch.text = "OFF"

		ai_mode_switch.setOnCheckedChangeListener { _, isChecked ->
			mAImode = isChecked

			if(isChecked) {
				ai_mode_switch.text="ON"
			}else{
				ai_mode_switch.text="OFF"
			}
		}

		recording_button.setOnTouchListener { _, event ->
			when (event?.action) {
				MotionEvent.ACTION_DOWN -> {
					if (!mRecordingCarmera) {
						// reset squence length index, etc
						mBufferIndex = 0
						mAddressPoseDetect = false
						mFinishPoseDetect = false
						mEndToFinishDetect = false

						// Play Sound Effect to Start Video Recording
						sound.play(MediaActionSound.START_VIDEO_RECORDING)
						ai_mode_text.visibility = View.INVISIBLE
						ai_mode_switch.visibility = View.INVISIBLE
						switch_camera_button.visibility = View.INVISIBLE

						// Start Recording
						if(!mAImode) {
							recording_time_signal.text = "REC"
							startVideoRecording()

							// Start recording video
							mRecordingCarmera = true

							// Start recording timer
							mRecordingTimer.start()
							mRecordingStartMillis = System.currentTimeMillis()

							if (VERBOSE) Log.d(TAG, "Video Recording started!!!!!")

							// Button image change
							recording_button.visibility = View.INVISIBLE
							recording_button.isEnabled = false
							recording_button.isSelected = true
						} else {
							// Start recording video
							mRecordingCarmera = true

							progressBar_cyclic.visibility = View.VISIBLE
							recording_time_signal.text = "AI Detecting...."
							recording_time_signal.visibility = View.VISIBLE
						}
					} else {
						// Play Sound Effect to Stop Video Recording
						sound.play(MediaActionSound.STOP_VIDEO_RECORDING)
						progressBar_cyclic.visibility = View.INVISIBLE
						ai_mode_text.visibility = View.VISIBLE
						ai_mode_switch.visibility = View.VISIBLE
						switch_camera_button.visibility = View.VISIBLE

						// Button image change
						if(mAImode) {
							if(!mAddressPoseDetect) {
								// Stop recording video
								mRecordingCarmera = false
								recording_time_signal.text = "REC"
								recording_time_signal.visibility = View.INVISIBLE
							}else if(mAddressPoseDetect && !mFinishPoseDetect) {
								recording_button.isSelected = false

								if (stopVideoRecording()) {
									if (VERBOSE) Log.d(TAG, "Video Recording Success!!!!!")

									// Set parameter and Launch player fragment
									val action =
										CameraFragmentDirections.actionCameraToPlayer(mOutputFile.absolutePath)
									mNavController.navigate(action)
								} else {
									if (VERBOSE) Log.d(TAG, "Video Recording Fail!!!!!")
								}
							}
						} else {
							recording_button.isSelected = false

							if (stopVideoRecording()) {
								if (VERBOSE) Log.d(TAG, "Video Recording Success!!!!!")

								// Set parameter and Launch player fragment
								val action =
									CameraFragmentDirections.actionCameraToPlayer(mOutputFile.absolutePath)
								mNavController.navigate(action)
							} else {
								if (VERBOSE) Log.d(TAG, "Video Recording Fail!!!!!")
							}
						}
					}
				}

				MotionEvent.ACTION_UP -> {
					// TODO Action
				}
			}
			true
		}

		mSwitchCamera = view.findViewById(R.id.switch_camera_button)
		mSwitchCamera!!.setOnClickListener {
			switchCameras()
		}

		// AI model load
		mAImodule = PyTorchAndroid.loadModuleFromAsset(resources.assets, "golfdb.torchscript.pt")
	}

	override fun onResume() {
		super.onResume()
		if(VERBOSE) Log.d(TAG, "CameraFragment Resume!!!!! (Camera Face : $mCameraFacing)")
		if(mPaused) {
			mPaused = false
			openCamera(mViewFinder.width, mViewFinder.height)
		}
	}

	override fun onPause() {
		super.onPause()
		if(VERBOSE) Log.d(TAG, "CameraFragment Pause!!!!! (Camera Face : $mCameraFacing)")
		mPaused = true
	}

	override fun onStop() {
		super.onStop()
		if(VERBOSE) Log.d(TAG, "CameraFragment Stop!!!!! (Camera Face : $mCameraFacing)")
		try {
			mCameraDevice!!.close()
			mCameraDevice = null
		} catch (exc: Throwable) {
			Log.e(TAG, "Error closing camera : $exc")
		}
	}

	override fun onDestroy() {
		super.onDestroy()
		if(VERBOSE) Log.d(TAG, "CameraFragment Destroy!!!!! (Camera Face : $mCameraFacing)")
		mCameraThread.quitSafely()
	}

	companion object {
		private val TAG = CameraFragment::class.java.simpleName
		private var mCameraFacing = BACKSIDE_CAMERA
		private const val VERBOSE = true
		private const val COUNTDOWN_INTERVAL: Long = 150L
		//private const val MIN_REQUIRED_RECORDING_TIME_MILLIS = 1000L
		private val sound = MediaActionSound()
		// default AI mode switch button
		private var mAImode = true

	}
}